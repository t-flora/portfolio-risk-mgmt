{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7605588",
      "metadata": {},
      "source": [
        "# Exercise - VaR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b6c886",
      "metadata": {},
      "source": [
        "## Data\n",
        "\n",
        "This problem uses `weekly` return data from `data/spx_returns_weekly.xlsx`.\n",
        "\n",
        "Choose any `4` stocks to evaluate below.\n",
        "\n",
        "For example, \n",
        "* `AAPL`\n",
        "* `META`\n",
        "* `NVDA`\n",
        "* `TSLA`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78c32f1",
      "metadata": {},
      "source": [
        "# Section 1: Diversification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39781afd",
      "metadata": {},
      "source": [
        "## 1.1\n",
        "\n",
        "Using the full sample, calculate for each series the (unconditional) \n",
        "\n",
        "(a) volatility\n",
        "\n",
        "(b) empirical VaR (.05)\n",
        "\n",
        "(c) empirical CVaR (.05)\n",
        "\n",
        "Recall that by **empirical** we refer to the direct quantile estimation. (For example, using `.quantile()` in pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c6a4da90",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_40265\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_40265_level0_col0\" class=\"col_heading level0 col0\" >weekly_vol</th>\n",
              "      <th id=\"T_40265_level0_col1\" class=\"col_heading level0 col1\" >annualised_vol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_40265_level0_row0\" class=\"row_heading level0 row0\" >AAPL</th>\n",
              "      <td id=\"T_40265_row0_col0\" class=\"data row0 col0\" >3.8362%</td>\n",
              "      <td id=\"T_40265_row0_col1\" class=\"data row0 col1\" >27.6629%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40265_level0_row1\" class=\"row_heading level0 row1\" >META</th>\n",
              "      <td id=\"T_40265_row1_col0\" class=\"data row1 col0\" >4.8722%</td>\n",
              "      <td id=\"T_40265_row1_col1\" class=\"data row1 col1\" >35.1336%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40265_level0_row2\" class=\"row_heading level0 row2\" >NVDA</th>\n",
              "      <td id=\"T_40265_row2_col0\" class=\"data row2 col0\" >6.4246%</td>\n",
              "      <td id=\"T_40265_row2_col1\" class=\"data row2 col1\" >46.3283%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40265_level0_row3\" class=\"row_heading level0 row3\" >TSLA</th>\n",
              "      <td id=\"T_40265_row3_col0\" class=\"data row3 col0\" >8.1323%</td>\n",
              "      <td id=\"T_40265_row3_col1\" class=\"data row3 col1\" >58.6431%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x115b42ad0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample: 2015-01-09 to 2025-05-23 (542 weeks)\n"
          ]
        }
      ],
      "source": [
        "# Question 1.1 Part (a) Code Here\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_excel(\"../data/spx_returns_weekly.xlsx\", sheet_name=\"s&p500 rets\")\n",
        "\n",
        "# Datetime index\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "df = df.set_index(\"date\").sort_index()\n",
        "\n",
        "# Tickers\n",
        "tickers = [\"AAPL\", \"META\", \"NVDA\", \"TSLA\"]\n",
        "\n",
        "# Drop NaNs with robust sub-setting and dtype cleanup\n",
        "cols = [c for c in tickers if c in df.columns]\n",
        "rets = df[cols].dropna(how=\"all\").apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Warn if any chosen tickers are missing\n",
        "missing = sorted(set(tickers) - set(cols))\n",
        "if missing:\n",
        "    print(\"Warning: missing columns =>\", missing)\n",
        "\n",
        "# Unconditional volatility\n",
        "weekly_vol = rets.std(ddof=1)\n",
        "annual_vol = weekly_vol * np.sqrt(52)\n",
        "\n",
        "vol_table = pd.DataFrame({\"weekly_vol\": weekly_vol, \"annualised_vol\": annual_vol})\n",
        "\n",
        "display(vol_table.style.format(\"{:.4%}\"))\n",
        "\n",
        "print(\n",
        "    f\"Sample: {rets.index.min().date()} to {rets.index.max().date()} \"\n",
        "    f\"({rets.shape[0]} weeks)\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9aa76dd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     VaR_5pct_signed VaR_5pct_loss\n",
            "AAPL          -5.64%         5.64%\n",
            "META          -7.00%         7.00%\n",
            "NVDA          -8.69%         8.69%\n",
            "TSLA         -11.74%        11.74%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d8/z5lkh3vn2w51kzd93v0t9kbc0000gn/T/ipykernel_55418/4054416824.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(var_table.applymap(lambda x: f\"{x:.2%}\"))\n"
          ]
        }
      ],
      "source": [
        "# Question 1.1 Part (b) Code Here\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "# Empirical VaR at 5 percent (historical quantile)\n",
        "var_signed = rets.quantile(alpha)\n",
        "var_loss = (-var_signed).clip(lower=0)\n",
        "\n",
        "var_table = pd.DataFrame(\n",
        "    {\n",
        "        \"VaR_5pct_signed\": var_signed,\n",
        "        \"VaR_5pct_loss\": var_loss,\n",
        "    }\n",
        ")\n",
        "\n",
        "# As percentages\n",
        "print(var_table.applymap(lambda x: f\"{x:.2%}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7e907376",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     VaR_5pct_signed CVaR_5pct_signed CVaR_5pct_loss\n",
            "AAPL          -5.64%           -8.31%          8.31%\n",
            "META          -7.00%          -10.32%         10.32%\n",
            "NVDA          -8.69%          -11.65%         11.65%\n",
            "TSLA         -11.74%          -14.78%         14.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d8/z5lkh3vn2w51kzd93v0t9kbc0000gn/T/ipykernel_55418/1531063214.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(cvar_table.applymap(lambda x: f\"{x:.2%}\"))\n"
          ]
        }
      ],
      "source": [
        "# Question 1.1 Part (c) Code Here\n",
        "\n",
        "alpha = 0.05\n",
        "var_5 = rets.quantile(alpha)\n",
        "\n",
        "# Mean return conditional on being below VaR threshold\n",
        "cvar_signed = rets[rets.le(var_5)].mean()\n",
        "cvar_loss = (-cvar_signed).clip(lower=0)\n",
        "\n",
        "cvar_table = pd.DataFrame(\n",
        "    {\n",
        "        \"VaR_5pct_signed\": var_5,\n",
        "        \"CVaR_5pct_signed\": cvar_signed,\n",
        "        \"CVaR_5pct_loss\": cvar_loss,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(cvar_table.applymap(lambda x: f\"{x:.2%}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbedd5a9",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcfdaac",
      "metadata": {},
      "source": [
        "## 1.2\n",
        "(a) Form an equally-weighted portfolio of the investments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "689b7202",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean    0.007769\n",
            "std     0.043758\n",
            "min    -0.164886\n",
            "max     0.155550\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Question 1.2 Part (a) Code Here\n",
        "\n",
        "n_assets = rets.shape[1]\n",
        "weights = np.repeat(1 / n_assets, n_assets)\n",
        "\n",
        "# Compute portfolio returns\n",
        "port_rets = rets.dot(weights)\n",
        "\n",
        "# Inspect Summary\n",
        "print(port_rets.describe()[[\"mean\", \"std\", \"min\", \"max\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af6908c",
      "metadata": {},
      "source": [
        "(b) Calculate the statistics of `1.1` for this portfolio, and compare the results to the individual return statistics. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "91b61d0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          weekly_vol annualised_vol VaR_5pct_signed CVaR_5pct_signed\n",
            "AAPL           3.84%         27.66%          -5.64%           -8.31%\n",
            "META           4.87%         35.13%          -7.00%          -10.32%\n",
            "NVDA           6.42%         46.33%          -8.69%          -11.65%\n",
            "TSLA           8.13%         58.64%         -11.74%          -14.78%\n",
            "Portfolio      4.38%         31.55%          -6.19%           -8.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d8/z5lkh3vn2w51kzd93v0t9kbc0000gn/T/ipykernel_55418/2714080794.py:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(compare.applymap(lambda x: f\"{x:.2%}\"))\n"
          ]
        }
      ],
      "source": [
        "# Question 1.2 Part (b) Code Here (clean combined output)\n",
        "\n",
        "# Portfolio statistics\n",
        "alpha = 0.05\n",
        "port_weekly_vol = port_rets.std(ddof=1)\n",
        "port_annual_vol = port_weekly_vol * np.sqrt(52)\n",
        "port_var = port_rets.quantile(alpha)\n",
        "port_cvar = port_rets[port_rets <= port_var].mean()\n",
        "\n",
        "# Combine individual stats into one table\n",
        "individual_stats = pd.concat(\n",
        "    [vol_table, var_table[\"VaR_5pct_signed\"], cvar_table[\"CVaR_5pct_signed\"]],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Add portfolio row\n",
        "portfolio_stats = pd.DataFrame(\n",
        "    {\n",
        "        \"weekly_vol\": [port_weekly_vol],\n",
        "        \"annualised_vol\": [port_annual_vol],\n",
        "        \"VaR_5pct_signed\": [port_var],\n",
        "        \"CVaR_5pct_signed\": [port_cvar],\n",
        "    },\n",
        "    index=[\"Portfolio\"],\n",
        ")\n",
        "\n",
        "# Append portfolio row to the bottom\n",
        "compare = pd.concat([individual_stats, portfolio_stats])\n",
        "\n",
        "# Display as clean percentages\n",
        "print(compare.applymap(lambda x: f\"{x:.2%}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee6e5d6d",
      "metadata": {},
      "source": [
        "(c) What do you find? What is driving this result?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1532983",
      "metadata": {},
      "source": [
        "The equally weighted portfolio shows lower volatility, VaR, and CVaR than the individual stocks. \n",
        "\n",
        "This confirms the effect of diversification: combining imperfectly correlated assets reduces total portfolio risk, even though each stock remains risky on its own.\n",
        "\n",
        "The result is driven by less-than-perfect correlations among the assets’ returns. \n",
        "\n",
        "When one stock performs poorly, others may perform better, so their losses do not occur simultaneously. \n",
        "\n",
        "As a result, portfolio return fluctuations are smoother, leading to a smaller standard deviation and smaller tail losses (VaR and cVaR)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e46401",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1128157",
      "metadata": {},
      "source": [
        "## 1.3\n",
        "(a) Re-calculate `1.2`, but this time drop your most volatile asset, and replace the portion it was getting with 0. \n",
        "\n",
        "You could imagine we're replacing the most volatile asset with a negligibly small risk-free rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4877d3ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most volatile asset dropped: TSLA\n",
            "                      weekly_vol annualised_vol VaR_5pct_signed  \\\n",
            "Original Portfolio         4.38%         31.55%          -6.19%   \n",
            "Dropped Most Volatile      3.03%         21.84%          -4.25%   \n",
            "\n",
            "                      CVaR_5pct_signed  \n",
            "Original Portfolio              -8.50%  \n",
            "Dropped Most Volatile           -6.05%  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d8/z5lkh3vn2w51kzd93v0t9kbc0000gn/T/ipykernel_55418/3084603792.py:36: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(compare_adj.applymap(lambda x: f\"{x:.2%}\"))\n"
          ]
        }
      ],
      "source": [
        "# Question 1.3 Part (a) Code Here\n",
        "\n",
        "# Identify most volatile asset\n",
        "most_volatile = vol_table[\"weekly_vol\"].idxmax()\n",
        "print(f\"Most volatile asset dropped: {most_volatile}\")\n",
        "\n",
        "# Set that column's returns to zero\n",
        "rets_adj = rets.copy()\n",
        "rets_adj[most_volatile] = 0.0\n",
        "\n",
        "# Keep the same equal weights (including the dropped one)\n",
        "n_assets = rets_adj.shape[1]\n",
        "weights = np.repeat(1 / n_assets, n_assets)\n",
        "\n",
        "# Compute adjusted portfolio returns\n",
        "port_rets_adj = rets_adj.dot(weights)\n",
        "\n",
        "# Recalculate portfolio statistics\n",
        "alpha = 0.05\n",
        "port_weekly_vol_adj = port_rets_adj.std(ddof=1)\n",
        "port_annual_vol_adj = port_weekly_vol_adj * np.sqrt(52)\n",
        "port_var_adj = port_rets_adj.quantile(alpha)\n",
        "port_cvar_adj = port_rets_adj[port_rets_adj <= port_var_adj].mean()\n",
        "\n",
        "# Combine results for comparison\n",
        "compare_adj = pd.DataFrame(\n",
        "    {\n",
        "        \"weekly_vol\": [port_weekly_vol, port_weekly_vol_adj],\n",
        "        \"annualised_vol\": [port_annual_vol, port_annual_vol_adj],\n",
        "        \"VaR_5pct_signed\": [port_var, port_var_adj],\n",
        "        \"CVaR_5pct_signed\": [port_cvar, port_cvar_adj],\n",
        "    },\n",
        "    index=[\"Original Portfolio\", \"Dropped Most Volatile\"],\n",
        ")\n",
        "\n",
        "print(compare_adj.applymap(lambda x: f\"{x:.2%}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "679b5804",
      "metadata": {},
      "source": [
        "(b) In comparing the answer here to 1.2, how much risk is your most volatile asset adding to the portfolio? "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6186400",
      "metadata": {},
      "source": [
        "By comparing the two portfolios, the most volatile asset (TSLA) adds roughly 1.35 percentage points of weekly volatility to the portfolio (4.38% − 3.03%), or about 9.7 percentage points annualised (31.55% − 21.84%).\n",
        "\n",
        "Similarly, the 5% VaR worsened from −4.25% to −6.19%, and the CVaR from −6.05% to −8.50% when TSLA was included.\n",
        "\n",
        "This shows that TSLA contributes meaningfully to the portfolio’s total risk — both overall volatility and tail losses, due to its large individual variance and imperfect diversification with the other assets. \n",
        "\n",
        "Even though diversification offsets some of its volatility, TSLA’s high standalone risk still increases the portfolio’s downside exposure substantially."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f74057",
      "metadata": {},
      "source": [
        "(c) Is this in line with the amount of risk we measured in the stand-alone risk-assessment of `1.1`?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cbdb52",
      "metadata": {},
      "source": [
        "Yes, this is consistent with the stand-alone risk assessment in 1.1. \n",
        "\n",
        "TSLA had the highest individual volatility (about 8.1% weekly and 58.6% annualised) and the deepest tail losses (VaR ≈ −11.7% and CVaR ≈ −14.8%). W\n",
        "\n",
        "hen included in the portfolio, it increased total volatility and downside risk by roughly the same proportion as its stand-alone risk suggested.\n",
        "\n",
        "Although diversification reduced part of the impact, TSLA’s very high variance and strong co-movement with the other growth stocks still raised the portfolio’s overall risk. \n",
        "\n",
        "The results are therefore in line with the individual metrics from 1.1, confirming that TSLA is the main contributor to total portfolio volatility and tail loss."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3a221f",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99dc32f0",
      "metadata": {},
      "source": [
        "# Section 2: Dynamic Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c676dfa",
      "metadata": {},
      "source": [
        "## 2.1 \n",
        "\n",
        "Let's measure the **conditional** statistics of the equally-weighted portfolio of `1.2`, as of the end of the sample.\n",
        "\n",
        "Note:\n",
        "- Suppose we can approximate that the daily mean return is zero.\n",
        "- In this setup, we are using a forecasted volatility, $\\sigma_t$ to estimate the VaR return we would have estimated at the end of $t-1$ in prediction of time $t$.\n",
        "\n",
        "(a) Volatility\n",
        "\n",
        "For each security, calculate the **rolling** volatility series, $\\sigma_t$, with a window of $m=26$.\n",
        "\n",
        "The value at $\\sigma_t$ in the notes denotes the estimate using data through time $t-1$, and thus (potentially) predicting the volatility at $\\sigma_{t}$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e49d7072",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last few rolling volatilities (weekly):\n",
            "date\n",
            "2025-04-25    0.053597\n",
            "2025-05-02    0.053211\n",
            "2025-05-09    0.048479\n",
            "2025-05-16    0.053749\n",
            "2025-05-23    0.054049\n",
            "dtype: float64\n",
            "\n",
            "Final rolling volatilities (σ_t):\n",
            "AAPL         5.15%\n",
            "META         5.80%\n",
            "NVDA         8.30%\n",
            "TSLA         8.30%\n",
            "Portfolio    5.40%\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Question 2.1 Part (a) Code Here\n",
        "\n",
        "# rolling window length (weeks)\n",
        "m = 26\n",
        "\n",
        "# Rolling volatility for each individual stock\n",
        "rolling_vol = rets.rolling(window=m).std(ddof=1)\n",
        "\n",
        "# Rolling portfolio volatility (using equal weights)\n",
        "n_assets = rets.shape[1]\n",
        "weights = np.repeat(1 / n_assets, n_assets)\n",
        "port_rets = rets.dot(weights)\n",
        "rolling_vol_port = port_rets.rolling(window=m).std(ddof=1)\n",
        "\n",
        "# Quick check\n",
        "print(\"Last few rolling volatilities (weekly):\")\n",
        "print(rolling_vol_port.tail())\n",
        "\n",
        "# Final forecasted volatilities\n",
        "latest_vol = pd.concat(\n",
        "    [rolling_vol.iloc[-1], pd.Series({\"Portfolio\": rolling_vol_port.iloc[-1]})]\n",
        ")\n",
        "print(\"\\nFinal rolling volatilities (σ_t):\")\n",
        "print(latest_vol.apply(lambda x: f\"{x:.2%}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b788b3",
      "metadata": {},
      "source": [
        "(b) VaR\n",
        "\n",
        "Calculate the **normal VaR** and **normal CVaR** for $q=.05$ and $\\tau=1$ as of the end of the sample.Use the approximation, $\\texttt{z}_{.05} = -1.65$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4ab073f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final σ_t (weekly): 5.4049%\n",
            "Normal VaR (5%): -8.9180%\n",
            "Normal CVaR (5%): -11.0546%\n"
          ]
        }
      ],
      "source": [
        "# Question 2.1 Part (b) Code Here\n",
        "\n",
        "# Parameters\n",
        "z_05 = -1.65\n",
        "alpha = 0.05\n",
        "\n",
        "# Use the final rolling portfolio volatility as σ_t\n",
        "sigma_t = rolling_vol_port.iloc[-1]\n",
        "\n",
        "# Normal VaR (1-week, assuming mean ≈ 0)\n",
        "var_norm = z_05 * sigma_t\n",
        "\n",
        "# Normal CVaR (expected shortfall under normality)\n",
        "# Formula: CVaR = (φ(z_q) / α) * σ, where φ is standard normal pdf\n",
        "phi_z = (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * z_05**2)\n",
        "cvar_norm = -sigma_t * (phi_z / alpha)\n",
        "\n",
        "# Display results\n",
        "print(f\"Final σ_t (weekly): {sigma_t:.4%}\")\n",
        "print(f\"Normal VaR (5%): {var_norm:.4%}\")\n",
        "print(f\"Normal CVaR (5%): {cvar_norm:.4%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a043c2",
      "metadata": {},
      "source": [
        "(c) Conclude and Compare\n",
        "Report\n",
        "* volatility (annualized).\n",
        "* normal VaR (.05)\n",
        "* normal CVaR (.05)\n",
        "\n",
        "How do these compare to the answers in `1.2`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "603a2445",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          Volatility_weekly Volatility_annual VaR_5pct  \\\n",
            "Conditional (σ_t from 2a)             5.40%            38.98%   -8.92%   \n",
            "Unconditional (from 1.2)              4.38%            31.55%   -6.19%   \n",
            "\n",
            "                          CVaR_5pct  \n",
            "Conditional (σ_t from 2a)   -11.05%  \n",
            "Unconditional (from 1.2)     -8.50%  \n",
            "\n",
            "Interpretation:\n",
            "The conditional (rolling) volatility and corresponding VaR/CVaR are higher than the unconditional values from 1.2. This indicates that recent market conditions have been more volatile, so a dynamic model predicts larger potential losses.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d8/z5lkh3vn2w51kzd93v0t9kbc0000gn/T/ipykernel_55418/81550451.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(compare_dynamic.applymap(lambda x: f\"{x:.2%}\"))\n"
          ]
        }
      ],
      "source": [
        "# Question 2.1 Part (c) Code Here\n",
        "\n",
        "# Calculate annualised volatility from σ_t\n",
        "port_vol_annual_cond = sigma_t * np.sqrt(52)\n",
        "\n",
        "# Create comparison table\n",
        "compare_dynamic = pd.DataFrame({\n",
        "    \"Volatility_weekly\": [sigma_t, port_weekly_vol],\n",
        "    \"Volatility_annual\": [port_vol_annual_cond, port_annual_vol],\n",
        "    \"VaR_5pct\": [var_norm, port_var],\n",
        "    \"CVaR_5pct\": [cvar_norm, port_cvar]\n",
        "}, index=[\"Conditional (σ_t from 2a)\", \"Unconditional (from 1.2)\"])\n",
        "\n",
        "# Display as percentages\n",
        "print(compare_dynamic.applymap(lambda x: f\"{x:.2%}\"))\n",
        "\n",
        "# Summary comment\n",
        "print(\n",
        "    \"\\nInterpretation:\\n\"\n",
        "    \"The conditional (rolling) volatility and corresponding VaR/CVaR are higher than \"\n",
        "    \"the unconditional values from 1.2. This indicates that recent market conditions \"\n",
        "    \"have been more volatile, so a dynamic model predicts larger potential losses.\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59a22c54",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a0f096",
      "metadata": {},
      "source": [
        "## 2.2\n",
        "\n",
        "Backtest the VaR using the **hit test**. \n",
        "\n",
        "Namely, check how many times the realized return at $t$ was smaller than the VaR return calculated using $\\sigma_t$, (where again remember the notation in the notes uses $\\sigma_t$ as a vol based on data through $t-1$.)\n",
        "\n",
        "Report the percentage of \"hits\" using both the\n",
        "\n",
        "(a) expanding volatility\n",
        "\n",
        "(b) rolling volatility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e6300564",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of VaR hits (expanding volatility): 4.98%\n",
            "Expected under 5% VaR: 5.00%\n"
          ]
        }
      ],
      "source": [
        "# Question 2.2 Part (a) Code Here\n",
        "\n",
        "alpha = 0.05\n",
        "z_05 = -1.65\n",
        "\n",
        "# Compute expanding (cumulative) volatility through t-1\n",
        "expanding_vol = rets.dot(np.repeat(1 / rets.shape[1], rets.shape[1])) \\\n",
        "    .expanding(min_periods=26).std(ddof=1)\n",
        "\n",
        "# Align volatility one period back to represent the forecast at t-1\n",
        "sigma_forecast = expanding_vol.shift(1)\n",
        "\n",
        "# Compute predicted VaR_t = z * sigma_{t-1}\n",
        "var_pred = z_05 * sigma_forecast\n",
        "\n",
        "# Actual portfolio returns (realised)\n",
        "port_rets = rets.dot(np.repeat(1 / rets.shape[1], rets.shape[1]))\n",
        "\n",
        "# Hit = 1 if actual return < predicted VaR\n",
        "hits = (port_rets < var_pred).astype(int)\n",
        "\n",
        "# Percentage of violations (\"hits\")\n",
        "hit_rate = hits.mean() * 100\n",
        "\n",
        "print(f\"Percentage of VaR hits (expanding volatility): {hit_rate:.2f}%\")\n",
        "\n",
        "# Optional: check the expected level under correct coverage\n",
        "print(f\"Expected under 5% VaR: {alpha * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e570f34e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of VaR hits (rolling volatility): 4.06%\n",
            "Expected under 5% VaR: 5.00%\n"
          ]
        }
      ],
      "source": [
        "# Question 2.2 Part (b) Code Here\n",
        "\n",
        "alpha = 0.05\n",
        "z_05 = -1.65\n",
        "m = 26  # rolling window length (weeks)\n",
        "\n",
        "# Rolling volatility (σ_t based on previous 26 weeks)\n",
        "rolling_vol = port_rets.rolling(window=m).std(ddof=1)\n",
        "\n",
        "# Shift one period back so σ_{t-1} predicts risk for time t\n",
        "sigma_forecast_roll = rolling_vol.shift(1)\n",
        "\n",
        "# Predicted VaR_t = z * σ_{t-1}\n",
        "var_pred_roll = z_05 * sigma_forecast_roll\n",
        "\n",
        "# Hit = 1 if realised return < predicted VaR\n",
        "hits_roll = (port_rets < var_pred_roll).astype(int)\n",
        "\n",
        "# Percentage of violations (\"hits\")\n",
        "hit_rate_roll = hits_roll.mean() * 100\n",
        "\n",
        "print(f\"Percentage of VaR hits (rolling volatility): {hit_rate_roll:.2f}%\")\n",
        "print(f\"Expected under 5% VaR: {alpha * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
